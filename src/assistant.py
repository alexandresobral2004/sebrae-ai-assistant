from typing import Optional, Dict, List
from .knowledge_base.base_conhecimento import BaseConhecimento
from .knowledge_base.processador_documentos import ProcessadorDocumentos
from .knowledge_base.gerenciador_consultores import GerenciadorConsultores
import openai
import os

# Configure a API Key do GitHub Copilot/OpenAI
# √â uma boa pr√°tica usar vari√°veis de ambiente para chaves de API
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

class AssistenteSebrae:
    def __init__(self, diretorio_base: str = ".chromadb", model_name: str = "gpt-3.5-turbo"):
        """
        Inicializa o Assistente Sebrae com sua identidade e base de conhecimento.

        Args:
            diretorio_base: Diret√≥rio para o banco de dados vetorial
            model_name: O nome do modelo OpenAI a ser usado (ex: 'gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo').
        """
        self.model_name = model_name
        self.client = openai.OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
        
        # PERSONA E MISS√ÉO PROFISSIONAL
        self.nome = "Consultor IA Sebrae"
        self.especialidade = "Especialista s√™nior em intelig√™ncia artificial e an√°lise de dados"
        self.funcao_principal = "Consultor de Produtos e Servi√ßos do Sebrae"
        self.missao = """Fornecer respostas precisas, pr√°ticas e atualizadas, ajudando os analistas Sebrae 
        a entender solu√ß√µes do Sebrae, fichas t√©cnicas (FT) e manuais de operacionaliza√ß√£o da aplica√ß√£o (MOA), 
        destacando melhores caminhos para que o analista possa contratar consultores e instrutores para o 
        atendimento √†s demandas."""
        
        # TOM E ESTILO
        self.tom_comunicacao = {
            "didatico": "Explique termos complexos de forma simples",
            "solicito": "Mostre-se pronto para ajudar",
            "profissional": "Use linguagem clara, objetiva e encorajadora",
            "analitico": "Demonstre expertise em IA e dados quando relevante"
        }
        
        # Inicializa componentes da base de conhecimento
        self.base_conhecimento = BaseConhecimento(diretorio_base)
        self.processador_documentos = ProcessadorDocumentos()
        
        # Gerenciador de consultores especializados
        self.gerenciador_consultores = GerenciadorConsultores()
        
    def carregar_documentos(self, diretorio_docs: str):
        """
        Carrega documentos de um diret√≥rio para a base de conhecimento.

        Args:
            diretorio_docs: Caminho do diret√≥rio com os documentos
        """
        print("Processando documentos...")
        chunks = self.processador_documentos.processar_diretorio(diretorio_docs)
        if chunks:
            print(f"Adicionando {len(chunks)} chunks √† base de conhecimento...")
            self.base_conhecimento.adicionar_documentos(chunks)
            print("Documentos carregados com sucesso!")
        else:
            print("Nenhum documento v√°lido encontrado para processar.")
    
    def _analisar_consulta(self, consulta: str) -> Dict[str, str]:
        """
        Realiza an√°lise Chain of Thought da consulta seguindo metodologia profissional.
        
        Args:
            consulta: A pergunta do usu√°rio
            
        Returns:
            Dict com an√°lise da consulta e estrat√©gia de busca
        """
        # An√°lise da pergunta
        tipo_necessidade = "produto_sebrae"  # A, B ou C
        if any(palavra in consulta.lower() for palavra in ["como", "o que √©", "conceito", "defini√ß√£o"]):
            tipo_necessidade = "conceito_negocio"
        elif any(palavra in consulta.lower() for palavra in ["tend√™ncia", "mercado", "futuro", "inova√ß√£o"]):
            tipo_necessidade = "tendencia_mercado"
        
        # Estrat√©gia de busca otimizada
        termos_busca = self._extrair_termos_relevantes(consulta)
        
        return {
            "tipo_necessidade": tipo_necessidade,
            "termos_busca": termos_busca,
            "estrategia": "base_interna_primeiro",
            "raciocinio": f"Analisando a consulta '{consulta}', identifico como {tipo_necessidade}. "
                         f"Vou iniciar pela base interna do Sebrae para garantir informa√ß√µes oficiais."
        }
    
    def _extrair_termos_relevantes(self, consulta: str) -> str:
        """
        Extrai e otimiza termos de busca da consulta.
        
        Args:
            consulta: Pergunta original
            
        Returns:
            String otimizada para busca
        """
        # Remove palavras irrelevantes e mant√©m termos-chave
        palavras_irrelevantes = {"como", "que", "qual", "onde", "quando", "por", "para", "um", "uma", "o", "a"}
        termos = [palavra.lower() for palavra in consulta.split() if palavra.lower() not in palavras_irrelevantes and len(palavra) > 2]
        return " ".join(termos)
        
    def processar_consulta(self, consulta: str) -> Dict[str, Optional[str]]:
        """
        Processa consultas seguindo metodologia Chain of Thought profissional:
        1. An√°lise da pergunta
        2. Busca priorit√°ria na base interna
        3. Busca ampla como fallback
        4. Resposta estruturada com transpar√™ncia de fonte

        Args:
            consulta: A pergunta ou pedido do usu√°rio

        Returns:
            Dict[str, Optional[str]]: Resposta contendo texto, fontes e metadados
        """
        if not self.client:
            return {
                "resposta": "A chave de API do OpenAI n√£o foi configurada. Verifique a vari√°vel de ambiente OPENAI_API_KEY.",
                "fontes": [],
                "palavras_chave": [],
                "raciocinio": "Erro de configura√ß√£o"
            }

        # PASSO 1: An√°lise Chain of Thought da consulta
        analise = self._analisar_consulta(consulta)
        
        # PASSO 2: Busca priorit√°ria na base interna (Regra de Ouro)
        resultados = self.base_conhecimento.buscar(analise["termos_busca"], num_resultados=8)
        
        # PASSO 3: Busca consultores especializados relacionados
        consultores_encontrados = self._buscar_consultores_relacionados(consulta, analise)
        
        if resultados:
            resposta_final = self._processar_resposta_base_interna(consulta, resultados, analise)
        else:
            # PASSO 4: Busca ampla como fallback
            resultados_amplos = self.base_conhecimento.buscar_ampla(consulta)
            if resultados_amplos:
                resposta_final = self._processar_resposta_busca_ampla(consulta, resultados_amplos, analise)
            else:
                # PASSO 5: Resposta quando n√£o encontra informa√ß√µes
                resposta_final = {
                    "resposta": f"""Como Consultor IA do Sebrae, analisando sua consulta sobre '{consulta}', 
                    n√£o encontrei informa√ß√µes espec√≠ficas em nossa base de documentos oficial. 

                    üìã **Recomenda√ß√£o:** 
                    - Reformule a pergunta sendo mais espec√≠fico
                    - Mencione se busca por um produto/servi√ßo espec√≠fico do Sebrae
                    - Indique o setor ou √°rea de interesse

                    üéØ **Pr√≥ximo Passo:**
                    Entre em contato com o atendimento Sebrae para consultas especializadas que possam n√£o estar 
                    cobertas em nossos manuais t√©cnicos.""",
                    "fontes": [],
                    "palavras_chave": [],
                    "raciocinio": analise["raciocinio"],
                    "estrategia_usada": "nenhuma_informacao_encontrada"
                }
        
        # Adiciona consultores √† resposta se encontrados
        if consultores_encontrados:
            resposta_final["consultores"] = consultores_encontrados
        
        return resposta_final
    
    def _buscar_consultores_relacionados(self, consulta: str, analise: Dict) -> List[Dict]:
        """
        Busca consultores especializados relacionados √† consulta.
        
        Args:
            consulta: Pergunta original
            analise: An√°lise Chain of Thought
            
        Returns:
            Lista de consultores encontrados
        """
        try:
            # Extrai termos relevantes da consulta para buscar consultores
            termos_busca = analise.get("termos_busca", consulta)
            
            # Busca consultores relacionados
            consultores = self.gerenciador_consultores.buscar_consultores(termos_busca, limite=3)
            
            return consultores
            
        except Exception as e:
            # Log do erro mas n√£o interrompe o fluxo principal
            print(f"Erro ao buscar consultores: {str(e)}")
            return []
    
    def _processar_resposta_base_interna(self, consulta: str, resultados: List[Dict], analise: Dict) -> Dict:
        """
        Processa resposta usando informa√ß√µes da base interna (Cen√°rio A - Sucesso).
        
        Args:
            consulta: Pergunta original
            resultados: Resultados da busca interna
            analise: An√°lise Chain of Thought
            
        Returns:
            Dict com resposta baseada na base interna
        """
        # Organiza o contexto com identifica√ß√£o das fontes
        contextos_organizados = []
        fontes_unicas = set()
        
        for i, resultado in enumerate(resultados):
            fonte = resultado["metadados"]["fonte"]
            fontes_unicas.add(fonte)
            chunk_id = resultado["metadados"].get("chunk_id", "")
            
            contexto_formatado = f"""[DOCUMENTO OFICIAL SEBRAE {i+1}: {fonte} - Se√ß√£o {chunk_id}]
{resultado["texto"]}
[FIM DO DOCUMENTO {i+1}]"""
            
            contextos_organizados.append(contexto_formatado)
        
        contexto_completo = "\n\n".join(contextos_organizados)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": f"""Voc√™ √© o "{self.nome}" - {self.especialidade}.
                        
Sua fun√ß√£o: {self.funcao_principal}
Miss√£o: {self.missao}

TOM DE COMUNICA√á√ÉO:
- DID√ÅTICO: Explique termos complexos de forma simples
- SOL√çCITO: Mostre-se pronto para ajudar
- PROFISSIONAL: Use linguagem clara, objetiva e encorajadora  
- ANAL√çTICO: Demonstre expertise em IA e dados quando relevante

ESTRUTURA OBRIGAT√ìRIA DA RESPOSTA (SIGA ESTA ORDEM):

1. APRESENTA√á√ÉO E MISS√ÉO:
   - Inicie se apresentando como Consultor IA Sebrae
   - Reforce brevemente sua miss√£o de ajudar os analistas

2. RESPOSTA √Ä PERGUNTA:
   - Responda objetivamente √† pergunta do usu√°rio
   - Use informa√ß√µes dos documentos oficiais Sebrae encontrados
   - Seja claro, did√°tico e completo
   - Cite especificamente as Fichas T√©cnicas (FTs) e MOAs quando aplic√°vel

3. CONSULTORES ESPECIALIZADOS:
   - Esta se√ß√£o ser√° adicionada automaticamente pelo sistema
   - N√ÉO mencione consultores na sua resposta
   - O sistema incluir√° automaticamente os consultores relacionados ao tema

4. DOCUMENTOS CONSULTADOS:
   - Esta se√ß√£o ser√° adicionada automaticamente pelo sistema
   - N√ÉO liste os documentos na sua resposta
   - O sistema incluir√° automaticamente a lista de fontes com links

IMPORTANTE:
- Concentre-se APENAS nas se√ß√µes 1 e 2
- N√ÉO crie se√ß√µes de consultores ou documentos
- Seja objetivo e pr√°tico"""
                    },
                    {
                        "role": "user",
                        "content": f"""AN√ÅLISE INICIAL: {analise['raciocinio']}

CONTEXTO DOS DOCUMENTOS OFICIAIS SEBRAE:
{contexto_completo}

PERGUNTA DO ANALISTA: "{consulta}"

INSTRU√á√ïES ESPEC√çFICAS:
- Inicie com apresenta√ß√£o como Consultor IA Sebrae e sua miss√£o
- Responda √† pergunta de forma objetiva e completa
- Use informa√ß√µes de TODOS os documentos relevantes
- Cite as FTs e MOAs encontrados
- N√ÉO mencione consultores (ser√° adicionado automaticamente)
- N√ÉO liste documentos (ser√° adicionado automaticamente)

RESPOSTA PROFISSIONAL:"""
                    }
                ],
                max_tokens=2500,
                temperature=0.2  # Ainda mais preciso para informa√ß√µes oficiais
            )
            
            resposta_gerada = response.choices[0].message.content
            return {
                "resposta": resposta_gerada,
                "fontes": list(fontes_unicas),
                "palavras_chave": [],
                "num_documentos_consultados": len(fontes_unicas),
                "estrategia_usada": "base_interna_oficial",
                "raciocinio": analise["raciocinio"]
            }
            
        except Exception as e:
            return {
                "resposta": f"Erro ao processar informa√ß√µes da base oficial: {str(e)}",
                "fontes": [],
                "palavras_chave": [],
                "estrategia_usada": "erro_processamento"
            }
    
    def _processar_resposta_busca_ampla(self, consulta: str, resultados: List[Dict], analise: Dict) -> Dict:
        """
        Processa resposta usando busca ampla (Cen√°rio B - Fallback).
        
        Args:
            consulta: Pergunta original
            resultados: Resultados da busca ampla
            analise: An√°lise Chain of Thought
            
        Returns:
            Dict com resposta baseada em busca ampla
        """
        if not resultados:
            return {
                "resposta": "N√£o foram encontradas informa√ß√µes relacionadas na base de conhecimento.",
                "fontes": [],
                "palavras_chave": [],
                "estrategia_usada": "busca_ampla_sem_resultados"
            }
        
        # Organiza contexto dos resultados amplos
        contextos = []
        fontes = set()
        
        for i, resultado in enumerate(resultados[:5]):  # Limita a 5 resultados
            fonte = resultado["metadados"]["fonte"]
            fontes.add(fonte)
            contextos.append(f"[DOCUMENTO PARCIAL {i+1}: {fonte}]\n{resultado['texto']}")
        
        contexto_amplo = "\n\n".join(contextos)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": f"""Voc√™ √© o "{self.nome}" do Sebrae.
                        
SITUA√á√ÉO: A informa√ß√£o espec√≠fica n√£o foi encontrada em nossa base principal, 
mas encontramos algumas refer√™ncias parciais em documentos.

INSTRU√á√ïES:
- Seja transparente que a informa√ß√£o √© limitada
- Use o que conseguiu encontrar de forma respons√°vel
- Sugira pr√≥ximos passos pr√°ticos
- Mantenha tom profissional e sol√≠cito"""
                    },
                    {
                        "role": "user",
                        "content": f"""AN√ÅLISE: {analise['raciocinio']}

A busca espec√≠fica n√£o retornou resultados completos, mas encontrei algumas refer√™ncias parciais:

{contexto_amplo}

Pergunta: "{consulta}"

Responda baseado nas informa√ß√µes limitadas dispon√≠veis, seja transparente sobre as limita√ß√µes 
e forne√ßa orienta√ß√µes pr√°ticas:"""
                    }
                ],
                max_tokens=1500,
                temperature=0.4
            )
            
            return {
                "resposta": response.choices[0].message.content,
                "fontes": list(fontes),
                "palavras_chave": [],
                "busca_ampla": True,
                "estrategia_usada": "busca_ampla_com_resultados_parciais",
                "raciocinio": analise["raciocinio"]
            }
            
        except Exception as e:
            return {
                "resposta": f"Erro ao processar busca ampla: {str(e)}",
                "fontes": [],
                "palavras_chave": [],
                "estrategia_usada": "erro_busca_ampla"
            }
    
    def _processar_resultados_amplos(self, consulta: str, resultados: List[Dict]) -> Dict[str, Optional[str]]:
        """
        Processa resultados de uma busca mais ampla quando a busca principal n√£o retorna resultados.
        
        Args:
            consulta: A pergunta do usu√°rio
            resultados: Lista de resultados da busca ampla
            
        Returns:
            Dict com resposta baseada nos resultados amplos
        """
        if not resultados:
            return {
                "resposta": "N√£o foram encontradas informa√ß√µes relacionadas na base de conhecimento.",
                "fontes": [],
                "palavras_chave": []
            }
        
        # Organiza contexto dos resultados amplos
        contextos = []
        fontes = set()
        
        for i, resultado in enumerate(resultados[:5]):  # Limita a 5 resultados
            fonte = resultado["metadados"]["fonte"]
            fontes.add(fonte)
            contextos.append(f"[DOCUMENTO {i+1}: {fonte}]\n{resultado['texto']}")
        
        contexto_amplo = "\n\n".join(contextos)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system",
                        "content": f"Voc√™ √© o '{self.nome}' do Sebrae. Analise o contexto fornecido e tente responder √† pergunta, mesmo que as informa√ß√µes sejam parciais. Indique claramente quando as informa√ß√µes s√£o limitadas e cite as fontes."
                    },
                    {
                        "role": "user",
                        "content": f"""Contexto parcial encontrado:
{contexto_amplo}

Pergunta: "{consulta}"

Responda baseado nas informa√ß√µes dispon√≠veis, indicando quais documentos consultou e se as informa√ß√µes s√£o limitadas:"""
                    }
                ],
                max_tokens=1500,
                temperature=0.4
            )
            
            return {
                "resposta": response.choices[0].message.content,
                "fontes": list(fontes),
                "palavras_chave": [],
                "busca_ampla": True
            }
            
        except Exception as e:
            return {
                "resposta": f"Erro ao processar busca ampla: {str(e)}",
                "fontes": [],
                "palavras_chave": []
            }
    
    def _buscar_internet(self, consulta: str) -> Optional[Dict[str, str]]:
        """
        Realiza busca na internet como fallback quando a informa√ß√£o n√£o est√° na base local.
        
        Args:
            consulta: A pergunta do usu√°rio
            
        Returns:
            Optional[Dict[str, str]]: Resultado da busca em fontes da internet
        """
        # Implementar integra√ß√£o com busca na internet aqui
        return None
    
    def formatar_resposta(self, resultado: Dict) -> str:
        """
        Formata resposta final seguindo padr√µes profissionais de transpar√™ncia.
        """
        resposta = resultado.get("resposta", "")
        fontes = resultado.get("fontes", [])
        estrategia = resultado.get("estrategia_usada", "")
        raciocinio = resultado.get("raciocinio", "")
        consultores = resultado.get("consultores", [])
        
        # SE√á√ÉO 3: CONSULTORES ESPECIALIZADOS
        # Adiciona APENAS consultores relacionados ao tema buscado
        if consultores:
            resposta += "\n\n---\n"
            resposta += "## üë• CONSULTORES ESPECIALIZADOS NO TEMA\n\n"
            resposta += "Com base no tema da sua consulta, identifiquei os seguintes consultores especializados:\n\n"
            
            for i, consultor in enumerate(consultores, 1):
                consultor_formatado = self.gerenciador_consultores.formatar_consultor(consultor)
                resposta += f"**Consultor {i}:**\n{consultor_formatado}\n\n"
            
            resposta += "üíº *Para contratar estes consultores, entre em contato diretamente atrav√©s dos dados informados acima.*\n"
        
        # SE√á√ÉO 4: DOCUMENTOS CONSULTADOS E LINKS
        # Lista os documentos oficiais consultados com links para download
        if fontes:
            resposta += "\n\n---\n"
            resposta += "## ÔøΩ DOCUMENTOS CONSULTADOS\n\n"
            resposta += "As informa√ß√µes fornecidas foram extra√≠das dos seguintes documentos oficiais do Sebrae:\n\n"
            
            for i, fonte in enumerate(sorted(fontes), 1):
                # Remove extens√£o e formata nome do arquivo
                nome_arquivo = fonte
                
                # Cria link para download (ajustar path conforme necess√°rio)
                # Assumindo estrutura: dados/documentos/categoria/arquivo.pdf
                link_download = f"/documentos/{fonte}"
                
                resposta += f"{i}. **{nome_arquivo}**\n"
                resposta += f"   üì• [Clique aqui para baixar]({link_download})\n\n"
            
            resposta += "\nÔøΩ *Estes documentos cont√™m informa√ß√µes detalhadas sobre Fichas T√©cnicas (FT) e Manuais de Operacionaliza√ß√£o (MOA).*\n"
        
        # Adiciona transpar√™ncia sobre estrat√©gia utilizada (rodap√©)
        resposta += "\n\n---\n"
        
        if estrategia == "base_interna_oficial":
            resposta += "‚úÖ *Resposta baseada em documentos oficiais Sebrae*\n"
        elif estrategia == "busca_ampla_com_resultados_parciais":
            resposta += "üîç *Resposta baseada em busca ampla - informa√ß√µes parciais*\n"
        elif estrategia == "nenhuma_informacao_encontrada":
            resposta += "‚ùì *Informa√ß√£o n√£o encontrada na base de conhecimento oficial*\n"
        
        # Rodap√© com pr√≥ximos passos
        if consultores or fontes:
            resposta += "\n‚ú® **Precisa de mais ajuda?** Posso fornecer informa√ß√µes adicionais sobre produtos e servi√ßos do Sebrae."
        else:
            resposta += "\nüí° **Quer aprofundar?** Posso ajudar a conectar voc√™ com consultores especializados ou identificar cursos espec√≠ficos do Sebrae para sua necessidade."
        
        return resposta